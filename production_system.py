"""
PRODUCTION PHISHING DETECTOR - GER√áEK VERƒ∞ SETƒ∞ ƒ∞LE KULLANIM
=============================================================

Adƒ±m 1: Veri setini indirin
Adƒ±m 2: CSV dosyasƒ±nƒ± proje klas√∂r√ºne koyun
Adƒ±m 3: A≈üaƒüƒ±daki kodu kullanƒ±n
"""

import pandas as pd
import numpy as np
import pickle  # Modeli kaydetmek i√ßin
import os
from phishing_detector import PhishingDetector  # Ana kodunuzdaki class

class ProductionPhishingSystem:
    """Production ortamƒ± i√ßin geli≈ütirilmi≈ü phishing tespit sistemi"""
    
    def __init__(self):
        self.detector = None
        self.model_path = "models/"
        self.data_path = "data/"
        
        # Klas√∂rleri olu≈ütur
        os.makedirs(self.model_path, exist_ok=True)
        os.makedirs(self.data_path, exist_ok=True)
    
    def load_real_dataset(self, dataset_type='kaggle'):
        """
        Ger√ßek veri setini y√ºkle
        
        Args:
            dataset_type: 'kaggle', 'local', veya 'custom'
        """
        
        if dataset_type == 'kaggle':
            # Kaggle'dan indirdiƒüiniz CSV dosyasƒ±nƒ± y√ºkleyin
            # √ñrnek: https://www.kaggle.com/datasets/subhajournal/phishingemails
            
            try:
                # Veri setinin yapƒ±sƒ±na g√∂re d√ºzenleyin
                df = pd.read_csv('data/clean_emails.csv')  
                
                # S√ºtun isimlerini kontrol edin ve d√ºzenleyin
                print("Mevcut s√ºtunlar:", df.columns.tolist())
                
                # Genelde veri setlerinde ≈üu s√ºtunlar olur:
                # 'text' veya 'email' - Email i√ßeriƒüi
                # 'label' veya 'spam' - 0/1 veya ham/spam etiketi
                
                # S√ºtun isimlerini standartla≈ütƒ±r
                if 'email' in df.columns:
                    df.rename(columns={'email': 'text'}, inplace=True)
                if 'spam' in df.columns:
                    df.rename(columns={'spam': 'label'}, inplace=True)
                
                # Etiketleri 0/1'e d√∂n√º≈üt√ºr
                if df['label'].dtype == 'object':
                    df['label'] = df['label'].map({'ham': 0, 'spam': 1, 
                                                   'legitimate': 0, 'phishing': 1})
                
                print(f"\n‚úÖ Veri seti y√ºklendi!")
                print(f"Toplam email sayƒ±sƒ±: {len(df)}")
                print(f"Phishing email sayƒ±sƒ±: {df['label'].sum()}")
                print(f"Normal email sayƒ±sƒ±: {len(df) - df['label'].sum()}")
                
                return df
                
            except FileNotFoundError:
                print("‚ùå emails.csv dosyasƒ± bulunamadƒ±!")
                print("L√ºtfen veri setini 'data/' klas√∂r√ºne koyun.")
                return None
                
        elif dataset_type == 'local':
            # Kendi formatƒ±nƒ±zdaki veriyi y√ºkleyin
            df = pd.read_csv('data/phishing_dataset.csv')
            
            # Veri yapƒ±nƒ±za g√∂re d√ºzenlemeler yapƒ±n
            # √ñrnek:
            # df['label'] = df['is_phishing'].astype(int)
            # df['text'] = df['email_content']
            
            return df
            
        elif dataset_type == 'custom':
            # Farklƒ± kaynaklardan veri toplama
            return self.create_custom_dataset()
    
    def create_custom_dataset(self):
        """
        Birden fazla kaynaktan veri birle≈ütirme
        """
        datasets = []
        
        # 1. SpamAssassin verisi
        if os.path.exists('data/spam_assassin.csv'):
            df1 = pd.read_csv('data/spam_assassin.csv')
            datasets.append(df1)
        
        # 2. Enron verisi
        if os.path.exists('data/enron.csv'):
            df2 = pd.read_csv('data/enron.csv')
            datasets.append(df2)
        
        # 3. Kendi topladƒ±ƒüƒ±nƒ±z veriler
        if os.path.exists('data/custom_phishing.csv'):
            df3 = pd.read_csv('data/custom_phishing.csv')
            datasets.append(df3)
        
        if datasets:
            # T√ºm veri setlerini birle≈ütir
            combined_df = pd.concat(datasets, ignore_index=True)
            print(f"‚úÖ {len(datasets)} farklƒ± veri seti birle≈ütirildi.")
            return combined_df
        else:
            print("‚ùå Hi√ßbir veri seti bulunamadƒ±!")
            return None
    
    def train_and_save_model(self, df):
        """
        Modeli eƒüit ve kaydet
        """
        print("\n" + "="*60)
        print("MODEL Eƒûƒ∞Tƒ∞Mƒ∞ BA≈ûLIYOR")
        print("="*60)
        
        # En iyi modeli se√ß (√∂nceki testlere g√∂re)
        best_model = self.find_best_model(df)
        
        # Final modeli eƒüit
        self.detector = PhishingDetector(model_type=best_model)
        X_train, X_test, y_train, y_test = self.detector.prepare_data(df)
        self.detector.train_model(X_train, y_train)
        
        # Performansƒ± g√∂ster
        metrics = self.detector.evaluate_model(X_test, y_test)
        
        # Modeli kaydet
        self.save_model()
        
        return metrics
    
    def find_best_model(self, df):
        """
        Hangi modelin en iyi performans g√∂sterdiƒüini bul
        """
        print("\nüîç En iyi model aranƒ±yor...")
        
        models = ['naive_bayes', 'logistic_regression', 'svm']
        best_score = 0
        best_model = 'naive_bayes'
        
        for model_type in models:
            print(f"\nTest ediliyor: {model_type}")
            detector = PhishingDetector(model_type=model_type)
            X_train, X_test, y_train, y_test = detector.prepare_data(df)
            detector.train_model(X_train, y_train)
            
            # F1 score'a g√∂re en iyiyi se√ß
            y_pred = detector.model.predict(X_test)
            from sklearn.metrics import f1_score
            score = f1_score(y_test, y_pred)
            
            print(f"F1 Score: {score:.4f}")
            
            if score > best_score:
                best_score = score
                best_model = model_type
        
        print(f"\nüèÜ En iyi model: {best_model} (F1: {best_score:.4f})")
        return best_model
    
    def save_model(self):
        """
        Eƒüitilmi≈ü modeli ve vectorizer'ƒ± kaydet
        """
        # Model dosyasƒ±nƒ± kaydet
        model_file = os.path.join(self.model_path, 'phishing_model.pkl')
        with open(model_file, 'wb') as f:
            pickle.dump(self.detector.model, f)
        
        # Vectorizer'ƒ± kaydet
        vectorizer_file = os.path.join(self.model_path, 'vectorizer.pkl')
        with open(vectorizer_file, 'wb') as f:
            pickle.dump(self.detector.vectorizer, f)
        
        print(f"\n‚úÖ Model kaydedildi: {model_file}")
        print(f"‚úÖ Vectorizer kaydedildi: {vectorizer_file}")
    
    def load_model(self):
        """
        Kaydedilmi≈ü modeli y√ºkle
        """
        try:
            # Detector'ƒ± ba≈ülat
            self.detector = PhishingDetector()
            
            # Model'i y√ºkle
            model_file = os.path.join(self.model_path, 'phishing_model.pkl')
            with open(model_file, 'rb') as f:
                self.detector.model = pickle.load(f)
            
            # Vectorizer'ƒ± y√ºkle
            vectorizer_file = os.path.join(self.model_path, 'vectorizer.pkl')
            with open(vectorizer_file, 'rb') as f:
                self.detector.vectorizer = pickle.load(f)
            
            print("‚úÖ Model ba≈üarƒ±yla y√ºklendi!")
            return True
            
        except FileNotFoundError:
            print("‚ùå Kaydedilmi≈ü model bulunamadƒ±. √ñnce modeli eƒüitin!")
            return False
    
    def predict_from_file(self, email_file):
        """
        Dosyadan email okuyup tahmin yap
        """
        with open(email_file, 'r', encoding='utf-8') as f:
            email_text = f.read()
        
        return self.detector.predict_email(email_text)
    
    def batch_prediction(self, csv_file):
        """
        Toplu email tahmini
        """
        df = pd.read_csv(csv_file)
        predictions = []
        
        for email in df['text']:
            result = self.detector.predict_email(email)
            predictions.append(result['prediction'])
        
        df['prediction'] = predictions
        df.to_csv('predictions_output.csv', index=False)
        print(f"‚úÖ Tahminler 'predictions_output.csv' dosyasƒ±na kaydedildi.")
        
        return df

# ==========================================
# KULLANIM √ñRNEKLERƒ∞
# ==========================================

def main_production():
    """
    Production sistemini √ßalƒ±≈ütƒ±r
    """
    system = ProductionPhishingSystem()
    
    print("="*60)
    print("PHISHING DETECTION SYSTEM - PRODUCTION")
    print("="*60)
    
    # Se√ßenekleri sun
    print("\nNe yapmak istersiniz?")
    print("1. Yeni model eƒüit")
    print("2. Mevcut modeli y√ºkle ve kullan")
    print("3. Toplu tahmin yap")
    
    choice = input("\nSe√ßiminiz (1/2/3): ")
    
    if choice == '1':
        # Yeni model eƒüitme
        print("\nVeri seti tipini se√ßin:")
        print("1. Kaggle veri seti (emails.csv)")
        print("2. Lokal veri seti")
        print("3. Birle≈ütirilmi≈ü veri setleri")
        
        data_choice = input("\nSe√ßiminiz (1/2/3): ")
        dataset_type = ['kaggle', 'local', 'custom'][int(data_choice)-1]
        
        # Veri setini y√ºkle
        df = system.load_real_dataset(dataset_type)
        
        if df is not None:
            # Model eƒüit ve kaydet
            metrics = system.train_and_save_model(df)
            
            print("\n‚úÖ Model eƒüitimi tamamlandƒ±!")
            print("Artƒ±k tahmin yapabilirsiniz.")
    
    elif choice == '2':
        # Mevcut modeli kullan
        if system.load_model():
            while True:
                print("\n" + "-"*60)
                email_text = input("\nEmail metnini girin (√ßƒ±kmak i√ßin 'q'):\n> ")
                
                if email_text.lower() == 'q':
                    break
                
                result = system.detector.predict_email(email_text)
                
                print("\n" + "="*40)
                if result['prediction'] == 'PHISHING':
                    print(f"‚ö†Ô∏è  UYARI: Bu email PHISHING olabilir!")
                else:
                    print(f"‚úÖ Bu email g√ºvenli g√∂r√ºn√ºyor.")
                
                print(f"G√ºven skoru: %{result['confidence']:.2f}")
                print("="*40)
    
    elif choice == '3':
        # Toplu tahmin
        if system.load_model():
            csv_file = input("\nTahmin yapƒ±lacak CSV dosyasƒ±nƒ±n adƒ±: ")
            system.batch_prediction(csv_file)

# ==========================================
# DOCKER ƒ∞√áƒ∞N DEPLOYMENT
# ==========================================

"""
Dockerfile √∂rneƒüi:

FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt
RUN python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

COPY . .

EXPOSE 5000

CMD ["python", "app.py"]
"""

# ==========================================
# WEB API ƒ∞√áƒ∞N FLASK ENTEGRASYONU
# ==========================================

"""
from flask import Flask, request, jsonify

app = Flask(__name__)
system = ProductionPhishingSystem()
system.load_model()

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    email_text = data.get('email_text', '')
    
    result = system.detector.predict_email(email_text)
    
    return jsonify(result)

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
"""

if __name__ == "__main__":
    main_production()